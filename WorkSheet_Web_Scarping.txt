1. B. Web Scrapping
2. C. Requests
3. A. Browser Based Applications
4. D. Spider
5. B. tag.name
6. C.lxml
7. D. 
8. C. list of all web elements associated with given xpath
9. D. a no of pixels vertically
10. A,B

11. 1. web crawlers usually focus on indexing the web while web scrapers extract or "scrape" data from webpages
    2. Web crawlers work by browsing the links to the other webpages are then followed and searched for more links. The process of following and recording 
       these links is referred to as “crawling.” It helps to reveal useful information about the
       structure of the web, extracting data from those sites. "web scraping", captures the content of those pages which can
       then be analyzed to reveal more information about the crawled pages.

12. A robots. txt file tells search engine crawlers which pages or files the crawler can or can't request from your site. 
    This is used mainly to avoid overloading your site with requests
	
13.  Static websites are ones that are fixed and display the same content for every user, usually written exclusively in HTML. 
     A dynamic website, on the other hand, is one that can display different content and 
     provide user interaction, by making use of advanced programming and databases in addition to HTML.

14.

from bs4 import BeautifulSoup
import requests
import pandas as pd
import csv
req_url = 'https://www.axisbank.com/'
res_ = requests.get(url=req_url)
scrap_Content = BeautifulSoup(res_.content)
scrap_Content
title = scrap_Content.find_all("title")
if len(title) > 0:
    print('Title is Present')
	
15. 
from selenium import webdriver
import os
req_url = 'https://images.google.com/'
res_ = requests.get(url=req_url)
res_
scrap_Content = BeautifulSoup(res_.content)
scrap_Content
title = scrap_Content.find_all("input")
driver = webdriver.Chrome(executable_path='chromedriver.exe')
my_page = driver.get(req_url)
search_box = driver.find_element_by_xpath("//input[@type='text']").send_keys("Natural language processing")
search_button = driver.find_element_by_xpath("//button[@type='submit']").click()
#next_page = driver.find_element_by_xpath("//li[@class='a-normal']//a").click()